title: Securing Your LLM Usage
---
description: Protect your data when working with LLMs. Learn system architecture for privacy, red teaming, guardrail models, and prompt sanitization.
---
meta_title: Securing Your LLM Usage â€” Privacy & Security Masterclass
---
trainer: Katharine Jarmul
---
date: Friday, 17 April 8:00 - 12:00
---
hours: 3.5
---
social_card_image: /masterclasses/securing-LLM-usage-katharine-jarmul/social_card.png
---
tags:

LLM Security
Privacy
Red Teaming
---
body:

In this masterclass, you'll learn ways to better protect your data when working with LLMs. We'll cover how to architect your systems for
better privacy and security, some introductions to red teaming and some basic protections for your text-based inputs (including guardrail
models and prompt sanitization). At the end of the course, you'll leave with some practical guides on how to use LLMs more safely with
private and sensitive data.

GitHub: [https://github.com/kjam/secure-and-private-ai-products-masterclass](https://github.com/kjam/secure-and-private-ai-products-masterclass)

## Katharine Jarmul

Katharine Jarmul is a privacy activist and an internationally recognized data scientist and lecturer who focuses her work and research on
privacy and security in data science and machine learning. You can follow her work via her
newsletter, [Probably Private](https://probablyprivate.com/) or in her recently published
book, [Practical Data Privacy (O'Reilly 2023\)](https://www.oreilly.com/library/view/practical-data-privacy/9781098129453/) now also
available in German and Polish.

She is a passionate and internationally recognized data scientist, programmer, lecturer, keynote speaker and writer.

A few of Katharine's books:

* [Practical Data Privacy](https://www.oreilly.com/library/view/practical-data-privacy/9781098129453/)
* [Data Wrangling with Python](https://www.oreilly.com/library/view/data-wrangling-with/9781491948804/)
* [Python Web Scraping](https://www.amazon.pl/Python-Web-Scraping-Hands-scraping/dp/1786462583)

---
notes:

