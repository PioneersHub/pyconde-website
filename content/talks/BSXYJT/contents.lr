title: Crafting Production Ready RAG/GenAI Recipes with OPEA
---
created: 2024-12-22
---
code: BSXYJT
---
speaker_names: Shivay Lamba, Suvrakamal Das
---
abstract: Enterprises face a number of challenges when it comes to development and deployment of  Python based Gen AI solutions. The development of new models, algorithms, fine tuning techniques, detecting and resolving bias and how we deploy large solutions at scale continues to evolve at a rapid pace. There is a lack of standardized software tools and technologies to choose from. 

OPEA, the Open Platform for Enterprise AI, is an open source project with the Linux Foundation. It provides a framework of composable microservices for state-of-the-art GenAI systems including LLMs, data stores, and prompt engines to expedite enterprise adoption. It provides blueprints of end-to-end workflows for popular usage such as ChatQnA, CodeGen, and RAG systems. This talk explores the practical steps for deploying Generative AI (GenAI) applications in cloud-native environments with OPEA. It will show deployments on a Kubernetes cluster on a range of hyperscalers. A wide variety of data stores, including open source vector databases and managed services, will be used to demonstrate production grade RAG capabilities. We will show the results of scale testing with > 50K documents. The attendees will learn how to deploy GenAI applications in a cloud-native way using OPEA. Explicit contribution opportunities will be shared with the attendees.
