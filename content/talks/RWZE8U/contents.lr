title: SLMs powered Edge-Ready NLP through Multi-Agent orchestration
---
created: 2024-12-22
---
code: RWZE8U
---
speaker_names: Rudraksh Karpe, SUMIT PANDEY
---
abstract:

Large Language Models (LLMs) excel at tasks like filtering, summarization, and code generation, but their high computational requirements lead to steep costs and limited scalability. This talk introduces a novel approach that shifts from monolithic LLMs to a lightweight ecosystem of open-source Small Language Models (SLMs) coordinated by a central Master Agent. By dynamically assigning tasks to specialized Worker Agents, each running an SLM tailored for specific functions, the architecture reduces resource consumption and costs while enhancing scalability. Additionally, this multi-agent framework supports edge-compatible solutions, enabling low-latency, privacy-preserving, and offline language processing across various devices. Implemented primarily in Python and leveraging open-source frameworks such as Langchain and Hugging Face, the proposed system optimizes resource utilization, simplifies maintenance through modular specialization, and ensures robust failover for uninterrupted performance. Attendees will explore how to integrate this flexible, future-proof platform into their projects, benefiting from its affordability and adaptability.
---
full_description:

Large Language Models (LLMs) are powerful tools for tasks like filtering, summarization, and code generation. However, their substantial computational demands result in high costs and limit scalability. To address these challenges, this talk proposes a new approach that moves away from traditional large models. Instead, it introduces a lightweight system made up of open-source Small Language Models (SLMs) managed by a central Master Agent. The Master Agent assigns tasks to specialized Worker Agents, each running an SLM such as Phi3 and 4 or Orca-mini, which are optimized for specific functions. This distribution of tasks among smaller models significantly reduces both resource usage and operational costs. Additionally, scaling the system or adapting to new tasks becomes easier by simply adding or replacing Worker Agents without the complexities of deploying a single large model.

Beyond cost and scalability, this approach meets the growing need for edge-compatible solutions. Compact SLMs can integrate smoothly into various edge devices, including IoT sensors and mobile applications. This integration allows for low-latency processing, enhances privacy by keeping data local, and even supports offline language processing. As a result, developers can deliver advanced language functionalities directly to users, regardless of infrastructure limitations or connectivity issues. This empowers the creation of applications that are both responsive and secure, catering to diverse environments and user needs.

Our implementation is primarily in Python and supported by open-source frameworks like Langchain and Hugging Face, encouraging community-driven improvements. The talk will demonstrate how this multi-agent framework optimizes resource use, simplifies maintenance through specialized modules, and ensures reliable performance with robust failover mechanisms. Attendees will learn how to integrate these components into their own projects, taking advantage of a flexible and scalable platform that is both cost-effective and adaptable for future advancements in language processing.
---
room: 
---
day: 
---
start_time: 
---
track: PyData: Natural Language Processing & Audio (incl. Generative AI NLP)
