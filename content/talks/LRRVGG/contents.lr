title: Why Don’t Customers Want My Free Goods? – Why Forecasting Models Don’t Answer 'What If' Questions
---
created: 2025-01-05
---
code: LRRVGG
---
speaker_names: Matthias Binder
---
abstract:

Forecasting and causal inference are distinct but fundamental tasks in data science. While forecasting predicts future outcomes based on history, causal inference explores the "why" behind those outcomes and helps simulate "what if" scenarios. Confusing the two can lead to misleading results.

At Blue Yonder, we encountered a case where a customer's forecasting model predicted demand accurately based on price. However, when they used the model for simulations to explore "what if" scenarios, the results were counterintuitive: lower prices led to lower demand. I will share how we resolved this issue and emphasize the importance of incorporating causal thinking when addressing questions like, "Why did this happen?" or "What if I do X?"

In this talk, I’ll show how to identify common pitfalls, like confounders, when integrating causal inference into forecasting workflows. We’ll also explore Bayesian models, powered by Markov Chain Monte Carlo (MCMC) methods, to bridge the gap between forecasting and causality using the PyMC library on practical examples.

By the end of this talk, you’ll learn how to:

- Consider causal reasoning when building models that forecast well but can also be used for interventions and "what if" scenarios.
- Visualize causal hypotheses with Directed Acyclic Graphs (DAGs) to understand relationships.
- Leverage PyMC to build Bayesian models for testing causal hypotheses and answering "what if" questions.
---
full_description:

Forecasting and causal inference are fundamental yet distinct tasks in data science. While forecasting predicts future outcomes based on historical patterns, causal inference seeks to understand the "why" behind these outcomes and explore "what if" scenarios to simulate the impact of interventions. These tasks often overlap but have different requirements—and confusing them can lead to unexpected results.

At Blue Yonder, we observed an intriguing case where a customer's forecasting model used price information to predict demand accurately. However, when they used the model for causal simulations—adjusting prices to explore "what if" scenarios—the predictions behaved counterintuitively: lower prices led to lower predicted demand! I would like to share the details of how we helped the customer resolve this issue in this real-world example and highlight the importance of taking a causal perspective when tackling questions like, "Why did this happen?", "What if I do X?", or "What if I had done Y instead?"

In this talk, I will demonstrate how to identify and avoid common pitfalls, such as confounders, when incorporating causal inference into traditional forecasting workflows. I’ll show how we can use Bayesian models powered by Markov Chain Monte Carlo (MCMC) methods to bridge the gap between forecasting and causality. Together, we’ll walk through practical examples using the PyMC library to illustrate these concepts.

By the end of this talk, you’ll gain actionable insights on how to:

- Consider causal reasoning when building models that forecast well but can also be used for interventions and "what if" scenarios.
- Visualize causal hypotheses using Directed Acyclic Graphs (DAGs) to understand causal relationships.
- Leverage PyMC to build Bayesian models for testing causal hypotheses and answering "what if" questions.

Whether you’re interested in forecasting, causal inference, Bayesian modeling, or all of them, this talk will equip you with practical tools to approach each with clarity and confidence—grounded in a real-world example from the Blue Yonder experience.
---
room: 
---
day: 
---
start_time: 
---
track: PyData: Machine Learning & Deep Learning & Statistics
---
python_skill: 
---
domain_expertise: 

