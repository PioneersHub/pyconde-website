title: Securing Generative AI: Essential Threat Modeling Techniques
---
created: 2025-01-05
---
code: UGTB7A
---
speaker_names: Elizaveta Zinovyeva
---
speakers:


### Elizaveta Zinovyeva



---
abstract:

Generative AI development introduces unique security challenges that traditional methods often overlook. This talk explores practical threat modeling techniques tailored for AI practitioners, focusing on real-world scenarios encountered in daily development. Through relatable examples and demonstrations, attendees will learn to identify and mitigate common vulnerabilities in AI systems. The session covers user-friendly security tools and best practices specifically designed for AI development. By the end, participants will have practical strategies to enhance the security of their AI applications, regardless of their prior security expertise.
---
full_description:

1. Introduction
    * Motivation
    * What can go wrong
2. Generative AI vs Traditional Applications
    * Key differences in security considerations
    * Unique challenges posed by generative AI
3. Threat Modeling Basics and AI-Specific Threats 
    * STRIDE framework
    * Focus on prompt injection and data poisoning
    * Example: Simple prompt injection attempt
4. Practical Threat Modeling Process
    * Simplified system decomposition example
    * Threat identification walkthrough
5.  Example: Input Validation
6. Tools Showcase and Mitigation Strategies
    * AI security tools applicable
    * Best practices for API security
7. Conclusion and Resources
    * Recap key takeaways
    * List of recommended tools and further reading
---
room: 
---
day: 
---
start_time: 
---
track: Generative AI
---
python_skill: 
---
domain_expertise: 
---
social_card_image: /static/media/social/talks/UGTB7A.png

