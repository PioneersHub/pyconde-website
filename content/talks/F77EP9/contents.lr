title: OpenAI o1/o3: the New Scaling Laws for LLMs that can reason
---
created: 2024-12-22
---
code: F77EP9
---
speaker_names: Luca Baggi
---
abstract: The renowned Chinchilla paper changed the way we train Large Language Models (LLMs). The authors - including the current Mistral CEO - derived the so-called **scaling laws** to maximise your model performance under a compute budget, balancing the number of parameters and data *during training*.

However, with o1, OpenAI ushered a new era of LLMs: reasoning capabilities. This new breed of models broadened the concept of scaling laws, shifting focus from **train-time** to **test-time** (or inference-time) compute. How do these models work? What do we think their architectures look like, and what data do we use to train them? And finally - and perhaps more importantly: how expensive can they get, and what can we use them for?
---
description: OpenAI o1, or Qwen's QwQ, make us feel we are in an "Alpha Zero moment" for LLMs. While have plenty of GPT4-like capable models, this new breed of LLMs promises to achieve new levels of performance through a very simple principle: by spending more time to answer tougher questions.

We tried to achieve this effect in several ways, both at the prompt engineering and the neural network level. However, none has proven this effective thus far. The talk will cover the following points.

**LLaMAs and Chinchillas** (6 min). A brief recap of the Chinchilla findings and how we departed ways from the old scaling laws with models like LLaMA.

**From train-time to test-time** (6 min). What test-time compute is, when it is advantageous to scale test-time compute, and what are the use-cases for reasoning models.

**How do models reason?** (8 min) What "reasoning" consists of, and how it's been currently implemented.

**Benchmark review** (5 min) A couple of words to caution the audience against the benchmarks that have been published so far, especially when it comes to pricing.

**Conclusion** (5 min). Wrap up and questions.
