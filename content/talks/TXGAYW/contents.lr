title: Detecting Complex Concepts in Unstructured Text Data
---
created: 2024-12-22
---
code: TXGAYW
---
speaker_names: Sukayna Younger-Khan
---
abstract:

How do we detect complex ideas like attitudes toward science or politics in large amounts of text? Traditional methods struggle with abstract concepts, but domain-aware contextual representations make this possible. This innovative approach uncovers hidden patterns in how ideas are framed, whether in speeches, articles, or social media. By analyzing text using an advanced LLM-driven, domain-informed approach, we can reveal new insights into topics that are hard to measure. Itâ€™s a powerful tool for unlocking meaning in unstructured data.
---
full_description:

How do we measure abstract concepts, like attitudes toward politics or science, from vast amounts of unstructured text? This talk introduces domain-aware contextual representations, a novel method that leverages advanced natural language processing to detect and analyze complex ideas embedded in speech corpora. Unlike traditional approaches, which often rely on predefined measures, this technique adapts to the specific context of the data, making it possible to extract meaningful insights from political speeches, social media, or other forms of discourse.

Using domain-aware contextual representations, we can uncover subtle patterns in how political leaders talk about science, even when the concept itself is implicit or abstract. By incorporating domain-specific knowledge into the analysis, the method generates richer, more accurate representations of complex attitudes, such as how science is framed in terms of its role in society, its values, or its institutional importance.

This approach leverages open LLMs, like Mistral 7B and Llama 3, along with powerful Python libraries like SentenceTransformers, to build contextual embeddings that capture both the general linguistic context and the specific nuances of discourse of interest: science in this case. I will demonstrate how this method can be applied to a large dataset of political speeches, showing how different political regimes and leaders use science rhetoric in diverse ways. Early results highlight striking differences: autocratic leaders often focus more on the normative value of science, while democratic leaders emphasize its institutional role. The method also reveals how science discourse peaks in specific domains, such as healthcare and technology, during times of crisis.

This talk will showcase how domain-aware contextual representations, powered by open-source tools, open new possibilities for detecting and analyzing abstract concepts in text data, offering exciting opportunities for both researchers and practitioners working with large-scale text analysis in Python.
