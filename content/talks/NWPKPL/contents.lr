title: Cutting the price of Scraping Cloud Costs
---
created: 2024-12-14
---
code: NWPKPL
---
speaker_names: Ed Crewe
---
abstract: A case study of rewriting a simple data pipeline involving Python, a pinch of Go, Git workflows, Airflow, Postgres and Cloud. Investigating some common assumptions and principles of designing data pipelines.
The benefits and issues with the tools and how these may be handled.
Get answers to the following options and more, as to what is the cheapest and most maintainable solution for this caseâ€¦

1. Do the data scraping ourselves OR use an established 3rd party aggregated data source
2. Use temporary embedded DBs OR a cloud master DB server 
3. Use a standard ELT pipeline pattern OR do ETL within each pipeline step
4. Implement purely via the pipeline workflow / DAGs and SQL OR create a separate Python package

I hope this case study of a pipeline rewrite will give you insights that are applicable to Python use for your own data pipelines, and into cloud pricing.
