title: zarr-python 3.0: Scalable data storage for n-dimensional arrays
---
created: 2025-01-04
---
code: U9W3FN
---
speaker_names: Norman Rzepka
---
abstract: Zarr is a data format designed for storing large n-dimensional arrays either on-disk or in the cloud. With its 3.0 release, the zarr-python library has undergone a significant overhaul. Among the key advancements is support for the latest Zarr specification, which introduces the new sharding feature—enabling efficient storage and access to n-dimensional arrays scaling to petabyte sizes. This release also brings a comprehensive refactor of the library, leveraging asynchronous operations to deliver substantial performance gains. Additionally, the library has been redesigned for greater extensibility and fully modernized with 100% type hint coverage.
In my talk, I will provide an introduction to the Zarr format and the zarr-python library, followed by a detailed overview of the major changes introduced in the 3.0 release.
---
description: Zarr is a widely adopted, chunked data format designed for efficiently storing large n-dimensional arrays, whether on-disk or in the cloud. Its design focuses on scalability and performance, making it a vital tool for handling massive datasets in fields like machine learning, climate modeling, and biomedical image analysis. The 3.0 release of the zarr-python library represents a major evolution, introducing substantial improvements and new features that enhance its capabilities and maintainability.

 The 3.0 release introduces support for the latest Zarr specification (version 3), designed to improve interoperability across multiple programming languages and enhance extensibility. One of the most prominent features of this specification is sharding. Sharding enables efficient storage and access to petabyte-scale n-dimensional arrays by allowing multiple chunks to be stored within a single file. This approach optimizes performance on various file systems and object storage services, making it more efficient and scalable for large datasets.

 The core of the zarr-python library has been reengineered to leverage asynchronous I/O, allowing reads and writes to be performed concurrently. This delivers significant performance improvements, especially when working with high-latency storage systems like object storage. Additionally, the library employs multithreading for encoding and decoding data, further enhancing throughput.

Version 3.0 has been redesigned with extensibility in mind, providing developers with the flexibility to integrate custom components such as stores, codecs, buffer classes, and encoding pipelines. This extensibility paves the way for use cases, such as optimized data processing on GPUs.

Moreover, the codebase has been thoroughly modernized to ensure maintainability and ease of development. The library now has 100% type hint coverage for better code clarity, robustness and code completion. The public and private APIs have been clearly delineated, with the goal of keeping the public APIs stable while evolving the library in the future. Additionally, the development environment has been upgraded with improved CI/CD workflows and testing infrastructure. These updates collectively make zarr-python a modern library that is vital for data-intensive science applications.

In my talk, I will provide an introduction to the Zarr format and the zarr-python library, followed by a detailed overview of the major changes introduced in the 3.0 release.
