title: Catch the LLM if you Can: Watermarking LLMs
---
created: 2025-11-19
---
code: 3JLSEF
---
speaker_names: Subhosri Basu
---
speakers:


### Subhosri Basu

I am a GenAI researcher at Fraunhofer Institute, Germany. Born in India, I decided to move to Germany in search of new challenges. My professional journey has been shaped by a passion to solve problems in various domains. Academically, I have graduated with a Master's degree from the department of electrical and computer science. My focus has always been around statistics. I have been able to work on projects related to artificial intelligence and deep learning, especially in the field of signal processing and imaging. With my experience, I want to guide the growth of next generation of ML researcher. When I am not working, you will find me exploring Europe.

---
abstract:

With Large Language Models (LLMs), generating high-quality text and images is easy and so is
misusing it. As AI-generated content becomes harder to distinguish from human generated content,
developers are increasingly asking: How can we verify whether a piece of text comes from an LLM?
We’ll explore Python’s simplicity and rich ecosystem of libraries to solve this problem.

This talk introduces the foundations of LLM watermarking and shows how developers can implement
these techniques entirely in Python. We’ll discuss two core approaches, EXP sampling method and
KGW method. We will walk through the implementation of the KGW method using simple,
transparent code, and compare it with the EXP approach. There's no need for a large model or a GPU
cluster to understand how these systems work and the core ideas can be implemented in pure
Python using simple code. The code repositories, which includes both methods will be provided so
that the attendees can follow along.

Along the way, we’ll discuss the trade-offs and the limitations of current research. And for those
wondering, “Do I have to implement all this myself?”, the talk concludes with a demo of MarkLLM, an
existing open-source toolkit that provides a unified Python interface for experimenting with
watermarking algorithms.

Attendees will leave with a clear understanding of how watermarking works, when it’s useful, and
how to integrate these techniques into real-world Python projects.
---
full_description:

During the talk we will cover:
1. Why Watermarking Matters?
     - What can go wrong when AI-generated content becomes indistinguishable from human writing
     -  Why provenance and transparency are becoming essential to trust and safety.
2. How LLM Watermarking Works?
     - What is a watermark and what isn't
     - The core idea behind statistical watermarking
3. Two Key Algorithms implemented using Python's established frameworks
     - EXP Watermark: modifying logits with pseudo-random perturbations.
     - KGW Green-List Watermark: partitioning tokens into “green” and “red” lists to bias sampling.
     - Python code walkthrough of implementing the KGW method and comparing it with the EXP method.
4.  How you can use MarkLLM (open-source toolkit)
     - Generate and detect watermarked text.
     - How to use the toolkit for experiments in your own workflows.
5. Real-World Challenges and Limitations
     - How robust and evasive are the current algorithms

Key Takeaways:
     - Watermarking is a promising tool for provenance.
     - Developers can implement and test watermarking fully in Python.
     - Understanding these methods helps build more transparent and trustworthy AI systems.
This talk is for people who:  
   - Care about ethics and privacy in AI and want to understand what watermarking can (and cannot)  solve.
   - Build applications using LLMs and want mechanisms for verifying or auditing generated text.
   - Are ML researchers or hobbyists interested in how watermarking algorithms function at a technical level.
   - Work in AI safety, trust & transparency, or responsible AI and need practical tools for content provenance.

Note: No prior experience with LLM architecture is required, basic familiarity with probability is recommended; no advanced math needed.
---
room: 
---
day: 
---
start_time: 
---
track: Ethics & Privacy
---
python_skill: Novice
---
domain_expertise: Novice
---
social_card_image: /static/media/social/talks/3JLSEF.png

