title: From SHAP to EBM: Explain your Gradient Boosting Models in Python
---
created: 2024-12-02
---
code: MBLX3W
---
speaker_names: Emanuele Fabbiani
---
abstract: Imagine you’ve just developed a **credit rating model** for a bank. The backtesting metrics look fantastic, and you get the green light to go live. But then, the first loan applications start rolling in, and suddenly your model’s decisions are under scrutiny. 

Why was this application rejected? Why was that one approved? You **must** have answers—and fast.

This session has you covered.

We’ll dive into SHAP (SHapley Additive exPlanations) and EBM (Explainable Boosting Machine), two widely used methods for interpreting tree-based ensemble models like XGBoost. You’ll learn about their theory, strengths, and limitations, as well as see them in action with Python examples using the `shap` and `interpret-ml` libraries.

From understanding feature contributions to hands-on coding, this talk will equip you with practical tools to make complex models transparent, understandable, and ready for critical applications.
