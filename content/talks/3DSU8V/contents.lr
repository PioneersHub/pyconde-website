title: Hands-On LLM Security: Attacks and Countermeasures You Need to Know!
---
created: 2024-12-20
---
code: 3DSU8V
---
speaker_names: Clemens Hübner, Florian Teutsch
---
speakers:


### Clemens Hübner

For more than ten years, Clemens Hübner has been working at the interface between software and security. After roles as a software developer and in penetration testing, he joined inovex in 2018 as a software security engineer. Today, he supports development projects at the conception and implementation level and is a trainer both in-house and for clients. He advises on secure development processes and DevSecOps. As speaker, he is invited to national and international conferences.

### Florian Teutsch

Florian Teutsch possesses extensive knowledge in the field of generative AI and works as a Machine Learning Engineer at inovex. After successfully completing his studies in Information Systems at the University of Cologne in 2020, he worked for two years as a Data Scientist on an innovative AI-based image search. Since joining inovex, he has been able to continuously expand his practical experience in the field of generative AI.

---
abstract:

Dive into the vulnerabilities of LLMs and learn how to prevent them
From prompt injection to data poisoning, we’ll demonstrate real-world attack scenarios and reveal essential countermeasures to safeguard your applications.
---
full_description:

The rapid increase in usage of large language models (LLMs) in the last years makes it necessary to address the specific security risks of LLMs.
In this presentation, we will examine typical vulnerabilities in LLMs from a practical perspective. Starting with a systematic overview, we will use a specific demo app to illustrate the various attack scenarios. Vulnerabilities like prompt injection, data poisoning and system prompt leakage will be explained and demonstrated as well as attacks on RAG and agent implementations.
In addition to a basic introduction and a presentation of specific vulnerabilities, the talk also presents suitable countermeasures and general best practices for the use of LLMs in productive applications.

What to expect? 
Attending this talk, you learn which vulnerabilities need to be considered when using and integrating LLMs. You will see how specific attacks work and what risks are associated with them. You will also learn which countermeasures are suitable and how these can be implemented technically.
---
room: 
---
day: 
---
start_time: 
---
track: Security
---
python_skill: 
---
domain_expertise: 
---
social_card_image: /static/meida/social/3DSU8V.png

