title: Monitoring Drifts in RAG Applications
---
created: 2025-01-05
---
code: 97MTW8
---
speaker_names: Brain Aboze
---
abstract:

Retrieval-augmented generation (RAG) combines the power of real-time data retrieval with large language model (LLM) capabilities, enabling accurate, up-to-date, and contextually relevant outputs. By querying external databases or documents during text generation, RAG addresses key challenges like hallucinations and enhances fact-based responses. However, the dynamic nature of user behavior, query patterns, and system updates makes monitoring data drift essential to ensure RAG applications' long-term reliability and performance.

Monitoring data drift in RAG applications is crucial to maintaining their reliability and performance over time. In this tutorial, we explore the drifts that can affect RAG systems and discuss their impact on performance. We will further explore how to monitor LLM drift using Evidently, an open-source tool designed for monitoring machine learning models. The session will include a live demonstration of Evidently’s Reports, Test Suites, and Monitoring Dashboard. Attendees will gain practical insights into maintaining the efficacy of RAG applications in the face of evolving data distributions, user behavior, and system updates.
---
full_description:

Retrieval-Augmented Generation (RAG) is revolutionizing the use of Large Language Models (LLMs) by enabling real-time data retrieval to produce accurate, up-to-date, and contextually relevant outputs. However, the dynamic nature of user behavior, data, system components, and operational environments poses challenges to maintaining the long-term reliability of RAG systems. This tutorial delves into the concept of drift, which occurs when subtle changes in these elements disrupt a system's performance, and presents actionable strategies to monitor and mitigate it effectively.

Through a hands-on demonstration using Evidently AI, attendees will learn to monitor these drifts in RAG systems. The session will leverage a Google Colab notebook with a practical example dataset, teaching participants how to prepare data using Evidently’s ColumnMapping object and evaluate it using various analytical techniques. Metrics such as text length, word count, and out-of-vocabulary percentages will be employed to detect shifts in user behavior. Additionally, pattern-based analysis and sentiment drift tracking will be covered, with a focus on identifying domain-specific trends and shifts in user sentiment over time.

The tutorial will also highlight advanced techniques, including using LLM-as-a-Judge, where OpenAI’s models can be leveraged to define and monitor custom qualitative metrics like toxicity. Semantic similarity analysis will be demonstrated to track alignment between user queries and system responses. By combining Evidently's robust monitoring tools with Langtrace's capabilities, participants will understand how to maintain the efficacy and reliability of RAG systems in dynamic environments.
---
room: 
---
day: 
---
start_time: 
---
track: PyData: Natural Language Processing & Audio (incl. Generative AI NLP)
