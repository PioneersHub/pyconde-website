title: The future of AI training is federated
---
created: 2024-12-22
---
code: 9Y9DM8
---
speaker_names: Chong Shen Ng
---
speakers:


### Chong Shen Ng

Dr. Chong Shen Ng is a Research Engineer at Flower Labs with over a decade of experience in both research and industry, specializing in federated learning, data science, and parallel computing. As a key developer, he focuses on scaling Flower to deploy privacy-enhanced distributed AI solutions for real-world applications. Chong Shen is passionate about contributing to the open-source community, developing trustworthy AI systems through federated learning, and advancing edge AI technologies. A dedicated advocate for open-source software, he has co-chaired PyData Global events and volunteered at SciPy and PyData London conferences.

---
abstract:

Since itâ€™s introduction in 2016, Federated Learning (FL) has become a key paradigm to AI models in scenarios when training data cannot leave its source. This applies in many industrial settings where centralizing data is challenging due to a combination of reasons, including but not limited to privacy, legal, and logistics.

The main focus of this tutorial is to introduce an alternative approach to training AI models that is straightforward and accessible. Weâ€™ll walk you through the basics of an FL system, how to iterate on your workflow and code in a research setting, and finally deploy your code to a production environment. You will learn all of these approaches using a real-world application based on open-sourced datasets, and the open-source federated AI framework, [Flower](https://github.com/adap/flower), which is written in Python and designed for Python users. Throughout the tutorial, youâ€™ll have access to hands-on open-sourced code examples to follow along.
---
full_description:

Federated Learning has quickly become the preferred form of training of AI models when the training data cannot leave their point of origin due to privacy regulations (e.g. GDPR), legal constraints (e.g. in different jurisdictions), and logistical challenges (e.g. large volumes of data, sparse connectivity), among other reasons. Furthermore, contracts and regulations establish boundaries for data sharing, particularly in industries like healthcare and finance, where misuse prevention is crucial. One could also argue that we are [running out of publicly and ethically sourced datasets](https://www.theverge.com/2024/12/13/24320811/what-ilya-sutskever-sees-openai-model-data-training), for instance to [scale large foundational models](https://arxiv.org/abs/2410.08892), and federated learning offers one way to train models on protected data.

The key point of this tutorial is to introduce an alternative approach to training AI models that is straightforward and accessible.

This tutorial is sequenced in 3 parts. Weâ€™ll first introduce federated learning and its prototypical architecture. In part 2, weâ€™ll dive into a series of live Python code demos that showcase how to convert a classical centralized machine learning workflow into a federated workflow involving multiple federated clients. Weâ€™ll demonstrate the similarities and differences of how the iteration of a federated research project is conducted. Finally, in part 3, weâ€™ll demonstrate how you can take your research code and deploy it in a production setting using a mixture of physical edge devices and VMs.

Throughout the tutorial, weâ€™ll use [Flower](https://github.com/adap/flower), the fully open-sourced federated AI framework, which is written in Python and designed for Python users. With simplicity as one of itâ€™s main goals, Flower provides multiple features and libraries to accelerate research, such as [Flower Baselines](https://flower.ai/docs/baselines/) (for reproducing federated learning benchmarks) and [Flower Datasets](https://flower.ai/docs/datasets/) (a standalone Python library for easily creating federated datasets). Weâ€™ll showcase how to use the Flower CLI in both research and production setting.

This tutorial addresses people with fluency in Python, CLI, and basic knowledge of a machine learning project. It would help if youâ€™ve also used Docker before. Any data practitioner is encouraged to attend the tutorial to learn and discuss how to federate and distribute the training of an ML model. 

You will learn:

- Whatâ€™s Federated Learning?
    - Basics and real-world examples
- How to federate your existing ML training code, and more FL-specific steps such as how to:
    - Configure the behaviours of each federated client
    - Persist the state of each client across global rounds
    - Evaluate both aggregated and local models
    - Standardize your FL experiments
    - Track your experiments
- How to deploy your research code in a production setting, such as how to:
    - Deploy Flower federated learning clients using Docker
    - Set-up secure connection and node authentication
    - Run, monitory, and manage the federated learning runs.

Bring your own laptop if youâ€™d like to follow along. Some code examples will be executed in GitHub Codespaces, others can be locally executed on your favourite IDE. 

**Update: 24th April 2025** 
The GitHub repo containing the code examples is available here ðŸ‘‰ [link](https://github.com/chongshenng/pyconde2025).

The tutorial session is structured in the following way:

- 0:00 Introduction, and getting to know the audience.
- 0:05 Whatâ€™s Federated Learning? Basics and real-world-examples.
- 0:25 Overview of the Flower framework for federated learning
- 0:30 Quickstart examples with PyTorch. Moving from a centralized training to federated.
- 1:00 Deploying your research to production
- 1:20 Feedback and Q&A
---
room: Dynamicum
---
day: Thursday
---
start_time: 16:15
---
track: Machine Learning & Deep Learning & Statistics
---
python_skill: 
---
domain_expertise: 
---
social_card_image: /static/media/social/talks/9Y9DM8.png

