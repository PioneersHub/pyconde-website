title: Simplifying Everyday tasks with Pre-trained ML models
---
created: 2024-12-21
---
code: QECRCM
---
speaker_names: Kelechi Chibundu
---
abstract:

Picture this, you have a text file you want to convert to speech. With just a few lines of code, you do this in minutes. That’s the power of pre-trained machine learning models. These ready-to-use models, available through libraries like Hugging Face Transformers and TensorFlow Hub,  make it easy to automate tasks such as text classification, image recognition, and speech-to-text with minimal setup.  

In this talk, we’ll learn how to effectively utilize pre-trained models to streamline workflows and simplify everyday tasks.
---
full_description:

We all agree that building ML models from scratch can be very overwhelming right? It often requires large amount of data, powerful hardware and a lot of time.
This challenge is what birthed the idea for this talk.
Pre-trained machine learning models provide a powerful solution for automating tasks with minimal effort, which enables  developers to achieve functionality without training models from scratch. This session demonstrates how to use libraries like Hugging Face Transformers and TensorFlow Hub to implement tasks such as text classification, image recognition, and speech-to-text in Python. Attendees will learn how to select the appropriate models, integrate them easily into applications, and customize them to meet unique requirements.

Outline:
-Introduction to Pre-trained ML models and their relevance  (3 mins)
-Overview of Pre-trained Model Libraries and Python Integration (7mins)
-Customizing Pre-trained models for specific tasks(8mins)
-Code breakdown (10mins)
-QnA (2mins)
