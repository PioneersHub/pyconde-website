title: Building Privacy-Focused Vector Search Applications: Hands-On Guide to Generative AI with Local LLMs
---
created: 2024-12-22
---
code: DJYRHE
---
speaker_names: Shivay Lamba, Gaurav Pandey
---
abstract:

Detailed insights into generating embeddings with tools like Ollama and demonstrating how LangChain agents can perform tasks such as document summarisation and API interactions, all while maintaining data privacy in a Python application
---
full_description:

Most of the applications are being powered by Generative AI. Some of the key proponents of Generative AI stem from concepts like RAG, Vector search and embeddings. This tutorial covers these core concepts on Vector search and is complete guide to help guide you from 0 to 1 in Vector Search with open source tools, libraries in Python understanding not only the core meaning of these terms but also hands on projects. 

A special focus of this tutorial is to also learn how to build privacy focused applications. A lot of times user send data to LLM cloud providers like OpenAI, raising privacy concerns. This tutorial will also emphasise on an alternative and privacy focused way to build AI applications by running LLMs locally with Ollama that keep everything local on your computer. This approach allows to avoid sending sensitive information to external servers. The tutorial also highlights LangChain's ability to create versatile AI agents capable of handling tasks autonomously by creating embeddings for the data. So come learn how can you build the next gen, privacy focused Vector search application powered by Local LLMs, open source vector databases while learning the key concepts of Generative AI such as Vector search, embeddings and practical use cases with an end to end example.
