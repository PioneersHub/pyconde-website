title: Zero Code Change Acceleration: familiar interfaces and high performance
---
created: 2024-12-22
---
code: PNQB7C
---
speaker_names: Tim Head
---
speakers:


### Tim Head

I am a scikit-learn core maintainer and work at NVIDIA.

Before working on scikit-learn I helped build mybinder.org and worked on JupyterHub.

Many years ago I was a particle physicist at CERN in Geneva.

---
abstract:

The PyData ecosystem is home to some of the best and most popular tools for doing data-science. Every data-scientist alive today has used pandas and scikit-learn and even Large Language Models know how to use them! For many years there have also been alternative implementations with similar interfaces and libraries with completely new approaches that focus on achieving the ultimate in performance and hardware acceleration. This talk will look at the recent efforts to give users the best of both worlds: a familiar and widely used interface as well as high performance.
---
full_description:

The interfaces defined by libraries like Numpy, pandas or scikit-learn are the defacto standard APIs in each library's domain. Data scientists use these libraries directly as well as indirectly through libraries that depend on them.

This talk will look at the different approaches that recent efforts have taken to give users both a familiar interface and GPU acceleration. This means users do not have to rewrite their code, learn a new library and benefit from acceleration when using existing libraries.

The cuml team built a scikit-learn accelerator by diving deep into the import system of Python. By hooking into the import system you can replace the result of `import sklearn` with a library that uses cuml where possible and falls back to scikit-learn where necessary.

The scikit-learn team is adding experimental support to handle PyTorch and CuPy inputs by using the array API standard. Instead of using the Numpy API to perform array computations, scikit-learn is switching to using the array API. This is a subset of the Numpy API that is supported by several other array libraries. The API of Numpy and PyTorch is similar but not exactly the same, this makes writing code that works with both hard. The array API addresses this problem by providing a unified API. Users can accelerate their scikit-learn code by passing in a CuPy or PyTorch array instead of a Numpy array.
---
room: Ferrum
---
day: Wednesday
---
start_time: 17:50
---
track: PyData & Scientific Libraries Stack
---
python_skill: 
---
domain_expertise: 
---
social_card_image: /static/media/social/talks/PNQB7C.png

