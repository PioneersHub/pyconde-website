title: Programming not prompting LLMs with DSPy and friends: Beyond Manual Tuning
---
created: 2024-12-31
---
code: 7QDEGX
---
speaker_names: Jeronim Morina
---
abstract:

LLMs promise efficiency but often get bogged down by manual tuning for optimal performance. DSPy changes the game. Traditional LLM deployment is a high-effort, error-prone process, demanding extensive prompt engineering and fine-tuning across multiple steps. 

Let's demystify DSPy's role in enhancing LLM efficiency, offering practical, transformative insights. 

We'll also explore alternatives and advice strategies when to use what.
---
full_description:

LLMs promise efficiency but often get bogged down by manual prompt tuning for optimal performance. DSPy changes the game. Traditional LLM deployment is a high-effort, error-prone process, demanding extensive prompt engineering and fine-tuning across multiple steps. Imagine deploying LLMs where manual optimizations are replaced by DSPy's automated, efficient prompt and weight optimization, streamlining processes and slashing costs. We'll cover how DSPy revolutionizes LLM deployment, its direct impact on operational efficiency, cost-effectiveness, and model reliability through practical applications. 
Last but not least we'll have a look at this emerging field and compare DSPY to its alternatives.
---
room: 
---
day: 
---
start_time: 
---
track: PyData: Natural Language Processing & Audio (incl. Generative AI NLP)
