title: Peering into the Black Box: Developing an NLP Analytics System to Assess Your Engine's Weaknesses
---
created: 2024-12-03
---
code: ELNFTD
---
speaker_names: Oren Matar
---
abstract:

As NLP models become increasingly prevalent in modern applications, the industry faces a critical challenge: how can we effectively evaluate the limitations of black-box NLP systems? This session introduces a model-agnostic evaluation paradigm that automatically generates test datasets enriched  with labeled linguistic challenges for each example. These labels enable precise analysis of failure cases, uncovering critical flaws and actionable insights. We will also present the development of a performance dashboard that visualizes engine capabilities, fostering better collaboration between data science and product teams. Designed for data scientists and product managers, this session offers practical tools to enhance NLP system performance and reliability.
---
full_description:

With NLP engines becoming integral to modern applications, the lack of standardized tools to assess their robustness poses significant risks to product reliability and user experience. This session introduces a new approach to evaluating NLP engines that addresses this gap.
By leveraging the capabilities of large language models (LLMs), we developed an automated method to generate comprehensive test datasets. Each dataset example includes labels pinpointing specific linguistic challenges. Using this Attribute-Aware dataset to evaluate an NLP engine, provides a clearer identification of itâ€™s strengths and weaknesses. This approach uncovered several critical issues in our own parser, providing deep insights into areas requiring improvement.
Beyond dataset generation, we implemented a dashboard that visually maps the engine's performance across various linguistic dimensions. This dashboard streamlines the development process and fosters collaboration between data scientists and product teams, ensuring the NLP engine aligns with real-world product requirements.
Our methodology is model-agnostic, making it applicable across diverse NLP systems. It is particularly valuable for black-box models such as LLMs and generative AI systems, where understanding internal limitations is often challenging. This session is designed to be accessible to a broad audience, including data scientists and product managers, offering practical tools and insights for building more robust NLP applications.
Attendees will leave with an understanding of how to implement these techniques, improve collaboration within their teams, and ensure their NLP engines deliver consistent and reliable results.
---
room: 
---
day: 
---
start_time: 
---
track: PyData: Natural Language Processing & Audio (incl. Generative AI NLP)
