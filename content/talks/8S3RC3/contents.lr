title: Build a personalized Commute agent in Python with Hopsworks, LangGraph and LLM Function Calling
---
created: 2025-01-05
---
code: 8S3RC3
---
speaker_names: Javier de la Rúa Martínez
---
speakers:


### Javier de la Rúa Martínez

Javier is a Research Engineer at Hopsworks, where he actively contributes to advancing the Hopsworks AI Lakehouse. He is currently pursuing his Ph.D. at KTH Royal Institute of Technology in Sweden with a primary focus on large-scale machine learning systems.

---
abstract:

The invention of the clock and the organization of time in zones have helped synchronize human activities across the globe. While timekeepers are better at planning and sticking to the plan, time optimists somehow believe that time is malleable and extends the closer the deadline. Nevertheless, whether you are an organized timekeeper or a creative timebender, external factors can affect your commute.

In this talk, we will define the different components necessary to build a personalized commute virtual agent in Python. The agent will help you analyze your historical lateness records, estimate future delays, and suggest the best time to leave home based on these predictions. It will be powered by a LLM and will use a technique called Function Calling to recognize the user intent from the conversation history and provide informed answers.
---
full_description:

The invention of the clock and the organization of time in zones have helped synchronize human activities across the globe. While timekeepers are better at planning and sticking to the plan, time optimists somehow believe that time is malleable and extends the closer the deadline. Nevertheless, whether you are an organized timekeeper or a creative timebender, external factors can affect your commute.

In this talk, we will define the different components necessary to build a personalized commute virtual agent in Python. The agent will help you analyze your historical lateness records, estimate future delays, and suggest the best time to leave home based on these predictions. It will be powered by a LLM and will use a technique called Function Calling to recognize the user intent from the conversation history and provide informed answers.

The ML system will be built in Python, following the best practices of the FTI (feature/training/inference) pipeline architecture, on top of the open-source Hopsworks AI lakehouse, which will provide the necessary ML infrastructure, such as the feature store, model serving, and a model registry. The agent will be designed with LangGraph and powered by a LLM running on the vLLM inference engine.
---
room: Dynamicum
---
day: Wednesday
---
start_time: 17:50
---
track: Data Handling & Engineering
---
python_skill: 
---
domain_expertise: 
---
social_card_image: /static/media/social/talks/8S3RC3.png

