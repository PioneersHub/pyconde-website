title: Use Instructor for structured, robust and easy testable LLM interactions
---
created: 2024-12-22
---
code: VSC9NC
---
speaker_names: Felizia Quetscher
---
abstract: How do you get structured, robust, easily testable outputs from an LLM? By using an (overly) complex prompt? Here is the better alternative: Instructor, a library for generating structured and robust outputs from your LLM.

In this talk, we will explore the capabilities and advantages of the Instructor library based on a real-world example using the OpenAI API. This talk aims to provide you with an overview of Instructor's useful tools to receive reliable, structured, robust, and easily testable LLM outputs. We will explore three tools of Instructor:
1. We will see how to use validators for evaluating the output of an LLM. With these validators, we can reprompt your model to encourage it to provide the correct output.
2. We will dive into the function calling capabilities that come with the Instructor library. With function calling, you ensure a structured LLM output using a Pydantic model.
3. We will explore Instructor's pre- and post-exectution hooks to evaluate the LLM's output.

After this talk, you will have an overview of the possibilities provided by Instructor to generate structured, robust, and easily testable outputs from your LLM.
