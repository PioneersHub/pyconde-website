title: Machine Learning Models in a Dynamic Environment
---
created: 2025-02-02
---
code: 3FUYVH
---
speaker_names: Isabel Drost-Fromm
---
speakers:


### Isabel Drost-Fromm

Isabel Drost-Fromm was up to recently the Chair of the board of directors of the InnerSource Commons Foundation, as well as (former board) member of the Apache Software Foundation. Interested in all things search and text mining with a thorough background in open source collaboration, she is working at Europace AG as Open Source Strategist. True to the nature of people living in Berlin she loves giving friends a reason for a brief visit - as a result she co-founded and is still one of the creative heads behind Berlin Buzzwords, a tech conference on all things search, scale and storage and FOSS Backstage.

---
abstract:

"We've only tested the happy path - now users are finding all sorts of creative ways to break the app."

What is already a cause for headaches in traditional software engineering turns into a large challenge when the application is based on machine learning models: Data distribution may change from training phase to deployment. Even worse, humans interacting with the model may adjust their behaviour to the model making the gap between original training environment and deployment even larger. When deployed in a public environment the model may be exposed to users trying to game the system. When re-trained it may be exposed to users trying to poison the pool of training data.

We will take a tour of historic cases of models being gamed: What are the lessons we learnt a long time ago building e-mail spam filters? What happened when high search engine rankings started to be linked to monetary income? How can personalization and targeted advertising be exploited to influence public discourse? 

“… it should be clear that improvements in communication tend to divide mankind …” by Harold Innis in Changing Concepts of Time

This keynote will turn interactive engaging the audience in sharing their stories on users playing interesting games with deployed models - including counter moves rolled out. 

If we are to learn from IT security experience, one important ingredient to address these issues is a combination of collaboration and transparency - across organisations.
---
full_description:

"Collect data, choose an algorithm, train a model to match your target metric and deploy to production." ... sounds easy enough.

But what if user behaviour changes after the model was deployed? What if the deployment of the model itself causes a change in user behaviour? 

This talk will look at examples for models changing user behaviour. In the interactive part the talk will collect stories from the audience.
---
room: Zeiss Plenary (Spectrum)
---
day: Thursday
---
start_time: 13:25
---
track: Keynote
---
python_skill: 
---
domain_expertise: 
---
social_card_image: /static/media/social/talks/3FUYVH.png

