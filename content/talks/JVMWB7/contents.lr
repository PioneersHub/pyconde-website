title: Streamlining LLMOps for Seamless Enterprise Production
---
created: 2024-12-22
---
code: JVMWB7
---
speaker_names: Shivay Lamba, Rudraksh Karpe
---
abstract: As enterprises increasingly adopting Large Language Models (LLMs) for diverse AI applications, they encounter challenges in transitioning these solutions from proof-of-concept to production. Traditional MLOps workflows, designed primarily for conventional ML models, struggle to accommodate LLM-specific challenges such as managing embeddings, orchestrating sophisticated data ingestion pipelines, and deploying context-aware intelligent agents at scale. Compounding these difficulties is the requirement to integrate seamlessly with existing enterprise infrastructure, maintain reproducibility and traceability, and ensure optimal performance.

In this session, we share our hands-on experience to shed light on the pain points encountered while putting LLMs into production. Attendees will learn about bottlenecks from handling unstructured text data ingestion to scaling vector databases for efficient retrieval and discover how to address them with best tested strategies. We will also discuss the broader open source LLMOps landscape, revealing best practices for pipeline design, version control, model monitoring, and cross-functional collaboration. By sharing these lessons and insights, we aim to deliver our audience with practical knowledge that can be applied to their MLOps/LLMOps stack with any framework or tooling, so they can effectively leverage the power of LLMs for enterprise-scale applications.
