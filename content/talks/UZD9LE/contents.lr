title: Beyond Fine-Tuning: A Strategic Roadmap for Adapting Large Language Models to Real-World Business Ne
---
created: 2025-01-04
---
code: UZD9LE
---
speaker_names: Michael Shtelma
---
abstract: Adapting Large Language Models (LLMs) to specific business needs can dramatically reduce compliance risks, optimise operations and improve customer satisfaction. This session provides a step-by-step roadmap, starting with Supervised Fine-Tuning (SFT) and progressing to more advanced, domain-driven approaches such as Retrieval-Augmented Adaptation for Fine-Tuning (RAFT). We also explore adaptation techniques, including reinforcement learning (e.g., DPO), that integrate feedback from both human experts and AI systems to ensure that results reflect organisational goals and user preferences.

What sets this talk apart is its focus on combining methodologies - layering RAFT on top of SFT, then adding DPO - to solve challenges in high-stakes areas such as financial compliance. We will show how real and synthetic data can be blended to reduce annotation costs and speed adaptation without sacrificing accuracy. By illustrating these techniques in concrete, compliance-based scenarios, attendees will see exactly how to balance model performance, resource constraints and domain complexity.

Ultimately, attendees will leave with a clear framework for selecting the right fitting strategy: from basic fine-tuning for moderate use cases to more sophisticated solutions for specialised domains. Attendees will also learn how to evaluate the trade-offs between cost, data availability, and model accuracy to maximise the business impact of AI in their own environments.
