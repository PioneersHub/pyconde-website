title: You don’t think about your Streamlit app optimization until you try to deploy it to the cloud
---
created: 2025-01-03
---
code: 3VYSMS
---
speaker_names: Darya Petrashka
---
abstract: Building Streamlit apps is easy for Data Scientists - but when it’s time to deploy them to the cloud, challenges like slow model loading, scalability, and security can become major hurdles. This talk bridges two perspectives: the Data Scientist who builds the app and the MLOps engineer who deploys it. We'll dive into optimizing model loading from Hugging Face Hub, implementing features like autoscaling and authentication, and securing your app against potential threats. By the end of this talk, you’ll be ready to design Streamlit apps that are functional and deployment-ready for the cloud.
---
description: #### Talk Outline:

1. Introduction
   - The disconnect: challenges when transitioning a Streamlit app from development to deployment.  
   - Why deployment considerations should influence app design.  

2. Optimizing model loading from HuggingFace hub 
   - Challenges:  
     - Large model sizes slowing down app performance.  
     - Inefficient loading processes increasing costs and user wait times.  
   - Solutions:  
     - Using Streamlit caching to reuse loaded models across sessions.  
     - Preloading models during image build.
     - Deploying models and calling them as APIs
   - MLOps Perspective: How optimized model loading reduces deployment complexity and cloud costs.  

3. AWS deployment considerations: autoscaling, authentication, and security  
   - Autoscaling:  
     - Challenges: Handling variable user traffic without incurring unnecessary costs.  
     - Solutions:  
       - Using Fargate with ECS for containerized apps with auto-scaling policies.  
       - Setting thresholds to scale instances based on traffic and resource utilization.  
       - Optimizing cost-performance balance with reserved vs. spot instances.  

   - Authentication:  
     - Challenges: Providing a secure and user-friendly authentication mechanism.  
     - Solutions:  
       - Integrating AWS Cognito for user management.  
       - Adding role-based access control to limit app functionality based on user roles.  

   - Security:  
     - Challenges: Protecting the app from attacks and unauthorized access.  
     - Solutions:  
       - Using AWS Web Application Firewall (WAF) to block malicious traffic.  
       - Configuring CloudFront to protect against DDoS attacks and improve performance.  
       - Setting up HTTPS with Route 53 and TLS certificates for secure connections.  
   - MLOps Perspective: Balancing simplicity and scalability in app deployment.  

4. Secrets Storage  
   - Challenges: Hardcoding sensitive credentials into the app.  
   - Solutions:  
     - Using AWS Secrets Manager or Parameter Store for secure secrets management.  
     - Employing environment variables for flexible app configuration.  
   - MLOps Perspective: How to ensure security without complicating deployment workflows.  

5. Key Takeaways 
   - Data Scientist’s Perspective:  
     - Why it’s critical to consider performance, scalability, authentication, and security during app development.  
   - MLOps Perspective:  
     - How to simplify deployment while ensuring performance and security.  
   - Encouraging collaboration between Data Scientists and MLOps engineers for smoother deployment processes.  

#### What you will learn:  
- How to efficiently load Hugging Face models in Streamlit apps to reduce costs and improve performance.  
- How to design apps with AWS autoscaling to handle variable traffic seamlessly.  
- Best practices for implementing user authentication with AWS Cognito.  
- How to secure your Streamlit app using cloud services.
- Best practices for secure secrets management in Streamlit apps.
- How to approach Streamlit app development with deployment in mind.
