title: sieves: A Toolkit for Prototyping NLP Tasks With Structured Generation
---
created: 2024-12-22
---
code: YTBGHG
---
speaker_names: Raphael Mitsch
---
abstract: While LLMs steal all the thunder these days, classic NLP tasks - classification, NER, etc. - remain ubiquitous. Whether or not generative AI is involved, decomposing NLP applications into a series of modular, pipelined tasks is a widely used and effective software engineering pattern.

Generative and predictive zero-/few-shot (ZFS) models complement this approach by enabling rapid prototyping of NLP tasks with little to no data. However, they come with their own challenges:

- **Generative models** CAN struggle to produce outputs in the required format, leading to the need for *structured generation*â€”a set of methods designed to enforce or fine-tune generative models to precisely match the desired output structure.
- **Predictive ZFS models**, while task-specific, typically lack generalization across different tasks.

What does that mean for your friendly neighbourhood ML engineer, looking for the best way to quickly prototype a NLP pipeline? Structured generation remains an active area of research, and existing tools have varying strengths and limitations. Switching between them is not always straightforward, making the choice potentially a sticky one. Ideally, engineers need a flexible solution that supports rapid experimentation with minimal setup and sensible defaults to get started quickly.

Cue `sieves`: a toolkit for rapid prototyping of NLP tasks with ZFS models. It provides a unified interface for a variety of models, tasks, and methods for structured output generati
