title: From Research Models to SLAs: Operationalizing TSFMs with Python
---
created: 2025-12-17
---
code: 3XDMXS
---
speaker_names: Jeyashree Krishnan, Catarina Filipe
---
speakers:


### Jeyashree Krishnan

Jeyashree Krishnan is a Senior Machine Learning Engineer at Siemens AG. Her work focuses on building and operationalizing scalable machine learning services, with an emphasis on foundation models and time series forecasting. She is also a Visiting Researcher at the Center for Computational Life Sciences, RWTH Aachen University.

### Catarina Filipe



---
abstract:

Time series foundation models (TSFMs) such as Chronos, Lag-Llama, TimesFM, and Siemensâ€™ own GTT have shown strong generalization capabilities across diverse forecasting tasks. However, integrating these models into a large organization is primarily a software engineering and MLOps challenge rather than a modeling one.

In this talk, we present a real-world case study based on Siemens KPI Forecast, a Python-based forecasting platform that operationalizes multiple TSFMs as reusable, production-grade services. The platform integrates both open research models and Siemens-developed models behind a unified API, supporting zero-shot inference, fine-tuning jobs, and fine-tuned inference depending on user needs and operational constraints.

We focus on how Python is used to compose heterogeneous components including open and closed-source models, internal data products, APIs, and orchestration layers into a consistent time series specialist user experience. The session also covers operating such services with clear SLAs in a B2B environment, including monitoring, versioning, and governance.

Attendees will gain practical insights into turning TSFMs into reliable Python services that scale across teams and use cases.
---
full_description:

### Motivation

Time series foundation models promise rapid prototyping and strong performance across domains, but many teams struggle to move beyond notebooks and benchmarks. In practice, the hardest problems are not model accuracy or architecture, but integration, operability, and developer experience.

This talk addresses a common but under-discussed question:

How do you operationalize time series foundation models inside a large organization with real users, real constraints, and real SLAs?

### Case study context

The talk is based on hands-on experience building and operating Siemens KPI Forecast, a Python-based forecasting platform that exposes multiple TSFMs through stable APIs. The platform integrates:

- Chronos ([https://arxiv.org/abs/2308.16103](https://arxiv.org/abs/2403.07815))
- Lag-Llama ([https://arxiv.org/abs/2310.08268](https://arxiv.org/abs/2310.08278))
- TimesFM ([https://arxiv.org/abs/2310.10688](https://arxiv.org/pdf/2310.10688))
- GTT, a Siemens-developed large-scale time series model (https://arxiv.org/pdf/2402.07570.pdf)

Chronos, Lag-Llama, and TimesFM are open-source research models, while GTT is a proprietary Siemens model. The platform is designed to treat both open and closed-source models uniformly from a developer and user perspective.

### Topics covered

- Why TSFMs are easy to prototype but hard to operationalize
- Designing Python APIs that unify multiple foundation models
- Supporting zero-shot inference, fine-tuning jobs, and fine-tuned inference in one system
- Integrating open-source and proprietary models consistently
- Making forecasting services accessible to different user personas
- Operating ML services with SLAs in a B2B environment
- Monitoring, versioning, and governance considerations

### What attendees will learn

- How to structure Python services around foundation models
- How to avoid fragmentation when supporting multiple models and workflows
- Practical MLOps patterns for operating ML services beyond notebooks
- Lessons learned from running TSFMs at organizational scale

This session focuses on engineering and operational lessons that are broadly applicable to teams building Python-based ML platforms in both enterprise and open-source contexts. Model references are included for transparency; the talk focuses on system design and operational patterns rather than proprietary details.
---
room: 
---
day: 
---
start_time: 
---
track: MLOps & DevOps
---
python_skill: Intermediate
---
domain_expertise: Advanced
---
social_card_image: /static/media/social/talks/3XDMXS.png

