title: Explainability for Gradient Boosting: SHAP and EBM
---
created: 2024-12-22
---
code: TJ7XGF
---
speaker_names: Emanuele Fabbiani
---
abstract:

Imagine you’ve just developed a **credit rating** model for a bank. The backtesting metrics look fantastic, and you get the green light to go live. But then, the first loan applications start rolling in, and suddenly your model’s decisions are under scrutiny.

**Why** was this application rejected? Why was that one approved? 

You must have answers—and fast.

This session has you covered.

We’ll dive into **SHAP** (SHapley Additive exPlanations) and **EBM** (Explainable Boosting Machine), two widely used methods for interpreting tree-based ensemble models like **XGBoost**. You’ll learn about their theory, strengths, and limitations, as well as see them in action with **Python examples** using the `shap` and `interpret-ml` libraries.

From understanding feature contributions to hands-on coding, this talk will equip you with practical tools to make complex models transparent, understandable, and ready for critical applications.
---
full_description:

**XGBoost** is considered a state-of-the-art model for regression, classification, and learning-to-rank problems on tabular data. Unfortunately, tree-based ensemble models are notoriously **difficult to explain**, limiting their application in critical fields. Techniques like SHapley Additive exPlanations (SHAP) and Explainable Boosting Machine (EBM) have become common methods for assessing how much each feature contributes to the model prediction.

This talk will introduce SHAP and EBM, **explaining the theory** behind their mechanisms in an accessible way and **discussing the pros and cons** of both techniques. We will also comment on Python snippets where SHAP and EBM are used to explain a gradient boosting model.

Attendees will walk away with an understanding of how SHAP and EBM work, the limitations and merits of both techniques, and a tutorial on how to use these methods in Python, courtesy of the [shap](https://shap.readthedocs.io/en/latest/) and [interpret-ml](https://interpret.ml/docs/ebm.html) packages.

Talk outline:

- A brief reminder about gradient boosting and XGBoost (5 mins)
- The challenge of explainability (5 mins)
- EBM: theory and applications (10 mins)
- SHAP: theory and applications (10 mins
