title: Human-Centered Design for Retrieval Augmented Generation: A Path to Trust and Usability
---
created: 2024-12-22
---
code: AMRYQL
---
speaker_names: Daniel Klitzke, Stefan Suwelack
---
abstract: There is no single RAG system that will suddenly solve all your problems. Although there are a lot of promises around integrating a chat window in your application and suddenly being blessed with happy users, this is unfortunately not the case. It is crucial to understand what the user needs to make the most of these new technologies. In our talk we will explore different aspects centered around the User Interface of a RAG system that will help you to build more effective machine learning systems. Concretely we will explore the following topics: 

1. Balancing Human and Machine Intelligence in RAG Systems: Provide effective but safe workflows through balancing user control and automation.
2. Building Trust Through Transparency and Explainability: Increase safety and build user trust through traceable decisions.
3. Designing Intuitive and Usable Interfaces for Diverse Users: Reducing cognitive load and adapting to user needs.
4. Feedback and Iteration Loops for Continuous Improvement: Refine your system over time and improve alignment with user expectations.

For each of those we will show you typical pitfalls to avoid and patterns to follow for leveling up your RAG systems and improving the experience for your users. Additionally, we will also provide you with concrete suggestions for implementation, using open-source tooling.
---
description: Human-Centered Design for Retrieval Augmented Generation: A Path to Trust and Usability 

Introduction

Currently, many companies are trying to leverage the power of LLMs to speed up a variety of tasks and to enable their employees to gain insights from data like never before. However, a lot of times the value actually provided stays well below the initial expectations. When looking into use cases where this was the case, we found the following: 

1. A lot of times, people tried generic solutions like Microsoft Copilot which simply lack the customizability needed to seamlessly support the workflow. 
2. Other times, people aim at building a custom solution but neglect the importance of providing a suitable user interface for leveraging the new technology. 

Both of those cases can be caused by a variety of different factors. One could for example be overestimating the abilities of LLMs and thus neglecting the importance of providing transparency in the decision-making process. Another one could also be simply not having the abilities for implementing a user interface themselves together with the lack of tooling that focuses on the user interface aspect. 

This is why we embrace the importance of Human-Centered Design for LLM powered systems, especially RAG systems. Concretely we have identified the following areas that we focus on when designing RAG systems that provide value to their users and are safe to use: 

1. Balancing Human and Machine Intelligence in RAG Systems: Provide effective but safe workflows through balancing user control and automation 
2. Building Trust Through Transparency and Explainability: Increase safety and build user trust through traceable decisions. 
3. Designing Intuitive and Usable Interfaces for Diverse Users: Reducing cognitive load and adapting to user needs. 
4. Feedback and Iteration Loops for Continuous Improvement: Refine your system over time and improve alignment with user expectations.

In the following sections we will thus outline those general themes, together with common pitfalls and patterns to follow. We also will provide guidance on how to leverage open-source tooling for concrete implementation of these principles. 


Balancing Human and Machine Intelligence in RAG Systems 

Being able to find the right balance of automation and user control is critical for designing an effective RAG system. Simply providing a chat window where the user can interactively ask any question, he or she wants will often not be efficiently supporting the task at hand through lack of guidance and automation. On the other hand, simply automating the whole process will often also not work as the model will make mistakes which depending on the use case can be costly or even unacceptable. Thus, you should care about thinking deeply about what the LLM can provide you and what the user must bring to the table. Below you find our lists of pitfalls and patterns to follow to avoid this trouble: 

1. Deeply think about your users' use case and workflow! Also, iterate frequently, it is impossible to get is perfect the first time. 
2. Think about humans in the loop approaches early on. A lot of times, people are too focused on making the model a tiny bit more accurate although the much more effective solution is changing the way the model is used. 
3. Make the transitions between things the LLM does and things the human does as easy and transparent as possible. E.g., going out of an app and opening a file in a PDF viewer to verify some information is usually not the way to go. Also, the user should know what the LLM just did and be able to take over seamlessly. 
4. Provide sensible defaults for workflows and let experienced users override them if necessary. A lot of times you will need to cater to both. Trying to fit everything in one interface will make your app unusable and weaken the guidance your app can provide to a user. Thus, find sensible defaults than can be adapted by experts without distracting the ones that don’t need the flexibility. 


Building Trust Through Transparency and Explainability 

Like also in other machine learning applications, a lot of the success of a machine learning system depends on being safe to use and building user trust. This is especially true for LLM-based systems as the fear and real risk of hallucinations is ubiquitous. Imagine having to make a decision in a business environment and simply trusting the aggregated answer of the LLM. This will not work, even in domains that are not especially high stakes. As a result, we have defined the following principles: 

1. Make it as easy as possible for the user to follow the decision-making process of the LLM. Even simple mechanisms like making the sources for an answer easily accessible can help already. 
2. Think about additional mechanisms that can further reduce cognitive load when interpreting a result, e.g., further narrow down the information used for generating an answer based on explainable AI techniques. 
3. Do not overwhelm the user with technical details in the explanations. Stay as close to the representations of information the user is used to and do not clutter the UI with additional elements. 
4. Provide granularity in explanations, meaning, first provide high-level summaries and let the user switch to detailed information on demand. 


Designing Intuitive and Usable Interfaces for Diverse Users 

Besides providing transparency about what the model does there is also a component about simply making the application easy and fun to use. Users probably won’t feel comfortable using an app where they feel they must do a lot of unnecessary actions.  One large part of this is really knowing the user, another part is having the technical ability to implement this using e.g. a front-end framework like React. In general, we propose to adhere to the following principles: 

1. Focus on tailoring your app to the user. Even tiny differences in the layout of the app or the way an action is dispatched can make a huge difference, especially in highly repetitive tasks. 
2. When creating a POC, be aware of that. If you can, incorporate thinking about suitable patterns for user interaction as soon as possible. If you cannot do that in a first iteration, at least explicitly outline how the app could be developed in a more usable direction. 
3. Use diverse methods for collecting feedback, such as having weekly meetings with real users, shadowing the users when doing their task using the new app, and many more. 


Feedback and Iteration Loops for Continuous Improvement 

As mentioned in the previous section, feedback is key for developing your system in a direction where the users will be effective with it and like using it. This has many layers and can affect adapting the underlying machine learning model itself but also making changes to the user interface. A lot of times however, we see that this feedback loop is neglected, especially in POCs, claiming that dealing with this later will be fine. The problem with this is that often those POCs then fail to prove value and do not move on to be a production ready ML system. So, it is important to think about how you can try incorporating Feedback into your ML project. We on our side usually try to follow these principles: 

1. Gather feedback continuously to improve your system. This should be one of your main sources for prioritizing tasks. Otherwise, your development will be undirected, no matter if it is about UI or model improvements. 
2. Make giving feedback as easy as possible and be transparent about how you use the feedback. This will incentivize users to give you feedback in the first place. The best is to make them immediately feel the changes they can make with this. 
3. If possible, try to avoid clutter in the User Interface as much as possible and use non-explicit feedback signals as much as possible, e.g., if a user adapts sources manually after a query was answered then your system might have gotten the wrong sources. 


Conclusion 

Being human-centered when designing RAG systems is important. As described previously, although it seems like the natural language interface by itself makes the LLM technology really accessible to the user this is not necessarily the case. It is still important to actively push towards finding the right interfaces and workflows to be effective in implementing a solution for a specific problem. Cross-cutting principles like frequent iteration, or balancing automation and user control, as well as specific mechanisms like explainability techniques can thus help tremendously with developing a solution that really is helping people to fulfilling their tasks. We hope with this presentation we can raise awareness, as well as provide hands-on guidance on what to avoid and what to embrace when building your next RAG-based machine learning system.
