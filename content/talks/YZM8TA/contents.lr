title: Demystifying Agentic AI Using Small Language Models
---
created: 2026-01-09
---
code: YZM8TA
---
speaker_names: Serhii Sokolenko
---
speakers:


### Serhii Sokolenko

Serhii Sokolenko is a co-founder of Tower, a Pythonic platform for data flows and agents running on top of open analytical storage. Prior to founding Tower, Serhii worked at Databricks, Snowflake and Google on data processing and databases.

---
abstract:

The AI world is buzzing with claims about “agentic intelligence” and autonomous reasoning. Behind the hype, however, a quieter shift is taking place: Small Language Models (SLMs) are proving capable of many reasoning tasks once assumed to require massive LLMs. When paired with fresh business data from modern lakehouses and accessed through tool calling, these models can power surprisingly capable agents.

In this talk, we cut through the noise around “agents” and examine what actually works today. You’ll see how compact models such as Phi-2 or xLAM-2 can reason and invoke tools effectively, and how to run them on development laptops or modest clusters for fast iteration. 
By grounding agents in business facts stored in Iceberg tables, hallucinations are reduced, while Iceberg’s read scalability enables thousands of agents to operate in parallel on a shared source of truth.
Attendees will leave with a practical understanding of data agent architectures, SLM capabilities, Iceberg integration, and a realistic path to deploying useful data agents - without a GPU farm.
---
full_description:

The Agentic Buzz  -  What’s Real, What’s Marketing

- The explosion of “agentic” frameworks and the confusion it causes
- What an agent really is at its core: planning, acting, and reasoning

Anatomy of an Agent

- The three basic functions: task decomposition, tool use, and code synthesis
- How frameworks like LangChain and Python make it easy to chain these together


Why Small Models Are Catching Up
- Review of research from NVIDIA and Georgia Tech
- Benchmarks showing SLMs matching or exceeding performance of larger LLMs
- Cost, latency, and deployability tradeoffs

Hands-On Demo: Building and Running an Agent on a Laptop

- Using LangChain and Python to orchestrate reasoning, tool calls, and code execution
- Example workflow: “Plan a dataset cleanup pipeline” using an SLM
- Observing resource use, latency, and performance in real time


Key Takeaways and Open Research Directions

- Opportunities for local and edge deployments
- The emerging role of SLMs in allowing everyone to experiment with agents
- Future questions: scaling reasoning vs. scaling models
---
room: 
---
day: 
---
start_time: 
---
track: Autonomous Systems & AI Agents
---
python_skill: Intermediate
---
domain_expertise: Novice
---
social_card_image: /static/media/social/talks/YZM8TA.png

